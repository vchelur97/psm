{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pickle.load(open(\"../data/train/meta.pkl\", \"rb\"))\n",
    "test_data = pickle.load(open(\"../data/test/meta.pkl\", \"rb\"))\n",
    "\n",
    "# Columns we will be measuring\n",
    "score_columns = [\"MSGFScore\", \"DeNovoScore\", \"SpecEValue\", \"EValue\"]\n",
    "\n",
    "# Build 'true_<score_column>' columns so that false rows can compare their\n",
    "# scores to their associated true row for similarity testing\n",
    "for dataset in [train_data, test_data]:\n",
    "    for score_column in score_columns:\n",
    "        for outer_key, inner_dict in dataset.items():\n",
    "            # Loop through inner dictionary\n",
    "            for inner_key, df in inner_dict.items():\n",
    "                # Get true value if exists\n",
    "                true_row = df[df[\"Label\"] == 1].iloc[0]\n",
    "                if true_row is not None:\n",
    "                    df[\"true_\" + score_column] = true_row[score_column]\n",
    "                else:\n",
    "                    df[\"true_\" + score_column] = None\n",
    "\n",
    "# Flatten the dataframes into one dataframe\n",
    "full_dfs = []\n",
    "for dataset in [train_data, test_data]:\n",
    "    df_list = []\n",
    "    for outer_key, inner_dict in dataset.items():\n",
    "        # Loop through inner dictionary\n",
    "        for inner_key, df in inner_dict.items():\n",
    "            # Create a copy of the dataframe to avoid modifying the original\n",
    "            df_copy = df.copy()\n",
    "            # Add outer and inner keys as columns\n",
    "            df_copy[\"outer_key\"] = outer_key\n",
    "            df_copy[\"inner_key\"] = inner_key\n",
    "            # Append the dataframe to the list\n",
    "            df_list.append(df_copy)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    full_df = pd.concat(df_list, ignore_index=True)\n",
    "    full_dfs.append(full_df)\n",
    "\n",
    "train_full_df = full_dfs[0]\n",
    "test_full_df = full_dfs[1]\n",
    "\n",
    "# Clean (might not be needed anymore) and create length column\n",
    "for dataset in [train_full_df, test_full_df]:\n",
    "    dataset.columns = dataset.columns.str.strip()\n",
    "    dataset[\"Peptide\"] = dataset[\"Peptide\"].str.strip()\n",
    "    dataset[\"peptide_length\"] = dataset[\"Peptide\"].str.len()\n",
    "\n",
    "    # Build peptide_unmodified column that is only numeric chars from Peptide col\n",
    "    # This feels complicated but I couldn't get it to work otherwise with regex\n",
    "    dataset[\"peptide_unmodified\"] = dataset[\"Peptide\"].str.replace(\"+\", \"\")\n",
    "    for i in range(10):\n",
    "        dataset[\"peptide_unmodified\"] = dataset[\"peptide_unmodified\"].str.replace(\n",
    "            str(i), \"\"\n",
    "        )\n",
    "    dataset[\"peptide_unmodified\"] = dataset[\"peptide_unmodified\"].str.replace(\".\", \"\")\n",
    "    dataset[\"peptide_unmodified\"] = (\n",
    "        dataset[\"peptide_unmodified\"].str[0]\n",
    "        + \".\"\n",
    "        + dataset[\"peptide_unmodified\"].str[1:-1]\n",
    "        + \".\"\n",
    "        + dataset[\"peptide_unmodified\"].str[-1]\n",
    "    )\n",
    "\n",
    "# Output the dataframes to csv\n",
    "train_full_df.to_csv(\"../data/train/meta_fulldf.csv\", index=False)\n",
    "test_full_df.to_csv(\"../data/test/meta_fulldf.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
